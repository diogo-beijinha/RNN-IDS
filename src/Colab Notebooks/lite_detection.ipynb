{"cells":[{"cell_type":"markdown","metadata":{"id":"VJr94s5M9e2q"},"source":["# Import Libs and get CSV file from Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LWdjAuLn9xTo","executionInfo":{"status":"ok","timestamp":1671193081151,"user_tz":0,"elapsed":2997,"user":{"displayName":"Diogo Beijinha","userId":"06164615948630766952"}},"outputId":"c61a82bc-ffe9-4c9f-9a3d-6dd10c40181d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" #If the line below doesn't work, uncomment this line (make sure to comment the line below); it should help.\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","'''\n","Numbers for \"os.environ['TF_CPP_MIN_LOG_LEVEL']\": \n","0 = all messages are logged (default behavior)\n","1 = INFO messages are not printed\n","2 = INFO and WARNING messages are not printed\n","3 = INFO, WARNING, and ERROR messages are not printed\n","'''\n","\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","from datetime import datetime\n","from csv import writer\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/')\n","!cp -r \"/content/drive/My Drive/Colab Notebooks/mega_detection.csv\" '/content/'\n","!cp -r \"/content/drive/My Drive/Colab Notebooks/lite_models/model.tflite\" '/content/'\n","!cp -r \"/content/drive/My Drive/Colab Notebooks/quant_lite_model/quant_model.tflite\" '/content/'"]},{"cell_type":"markdown","metadata":{"id":"qEk83lGR9yrP"},"source":["# Run Inference on CSV file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YJw1BdLd9bF0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671193128363,"user_tz":0,"elapsed":47222,"user":{"displayName":"Diogo Beijinha","userId":"06164615948630766952"}},"outputId":"7d100d1c-8b27-4528-a360-b1f6f1dc61f7"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-f1ef48d7f4fd>:165: DtypeWarning: Columns (25,32,52,58) have mixed types.Specify dtype option on import or set low_memory=False.\n","  detect()\n"]},{"output_type":"stream","name":"stdout","text":["What model would you like to use:\n","1.Lite Model\n","2.Quantized Lite Model\n","Option:2\n","Correct Predictions(%) : 64.31091385000569%\n","Total no. of rows:  8787\n","Predicted Correctly:  5651\n","Wrong Predictions:  3136\n"]}],"source":["def detect():\n","\n","    # Import CSV file\n","    try:\n","        df = pd.read_csv(\"/content/mega_detection.csv\", encoding=\"UTF-8\", keep_default_na=False, na_values='')\n","        \n","    except:\n","        df = pd.read_csv(\"/content/mega_detection.csv\", encoding=\"UTF-16\", keep_default_na=False, na_values='')\n","    \n","    # Get no. of rows in dataframe(df)\n","    df_size = len(df.index)\n","\n","    model_option = int(input(\"What model would you like to use:\\n1.Lite Model\\n2.Quantized Lite Model\\nOption:\"))\n","\n","\n","    # correct_predictions variable\n","    correct_pred = 0\n","    \n","    # Create 2d array for dataset data\n","    for i in range(0, df_size):\n","        data_array = np.array([[]], dtype=np.float32)\n","\n","\n","        sample={\n","            'dur': df['dur'][i],\n","            'proto': df['proto'][i],\n","            'service': df['service'][i],\n","            'state': df['state'][i],\n","            'spkts': df['spkts'][i],\n","            'dpkts': df['dpkts'][i],\n","            'sbytes': df['sbytes'][i],\n","            'dbytes': df['dbytes'][i],\n","            'rate': 0,\n","            'sttl': df['sttl'][i],\n","            'dttl': df['dttl'][i],\n","            'sload': 0,\n","            'dload': 0,\n","            'sloss': df['sloss'][i],\n","            'dloss': df['dloss'][i],\n","            'sintpkt': df['sintpkt'][i],\n","            'dintpkt': df['dintpkt'][i],\n","            'sjit': 0,\n","            'djit': 0,\n","            'swin': 0,\n","            'stcpb': df['stcpb'][i],\n","            'dtcpb': df['dtcpb'][i],\n","            'dwin': 0,\n","            'tcprtt': df['tcprtt'][i],\n","            'synack': 0,\n","            'ackdat': 0,\n","            'smean': 0,\n","            'dmean': 0,\n","            'trans_depth': 0,\n","            'response_body_len': df['response_body_len'][i],\n","            'ct_srv_src': df['ct_srv_src'][i],\n","            'ct_state_ttl': 0,\n","            'ct_dst_ltm': 0,\n","            'ct_src_dport_ltm': 0,\n","            'ct_dst_sport_ltm': 0,\n","            'ct_dst_src_ltm': df['ct_dst_src_ltm'][i],\n","            'is_ftp_login': df['is_ftp_login'][i],\n","            'ct_ftp_cmd': df['ct_ftp_cmd'][i],\n","            'ct_flw_http_mthd': 0,\n","            'ct_src_ltm': 0,\n","            'ct_srv_dst': df['ct_srv_dst'][i],\n","            'is_sm_ips_ports': df['is_sm_ips_ports'][i]\n","        }\n","\n","\n","        # Replace 'NaN' values with 0\n","        for key, value in sample.items():\n","            if value >= 0 and value <= 100:\n","                data_array = np.append(data_array, value)\n","            else:\n","                data_array = np.append(data_array, 0.0)\n","        \n","\n","        # Create copy of data_array and reshape it to be a 3d array\n","        new_data_array = np.array(data_array, dtype=np.float32)\n","        new_data_array = new_data_array.reshape((1, 42, 1))\n","        \n","        # Create Interpreter for Model\n","        if model_option == 1 and os.path.exists(\"/content/model.tflite\") == True:\n","          interpreter = tf.lite.Interpreter(model_path='/content/model.tflite')\n","        elif model_option == 2 and os.path.exists(\"/content/quant_model.tflite\") == True:\n","          interpreter = tf.lite.Interpreter(model_path=\"/content/quant_model.tflite\")\n","        else:\n","          print(\"You do not have that model in the Drive\")\n","\n","        # Allocate Tensors for Model Interpreter\n","        interpreter.allocate_tensors()\n","\n","        # Get Input and Output tensors\n","        input_details = interpreter.get_input_details()\n","        output_details = interpreter.get_output_details()\n","        \n","        # Set the 3D data array as the input_data (data passed on during the Lite Model Testing)\n","        input_data = new_data_array\n","\n","        interpreter.set_tensor(input_details[0]['index'], input_data)\n","\n","        # Run Testing on Lite Model\n","        interpreter.invoke()\n","\n","        # Get results\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","        pred_attack = np.argmax(output_data, axis=1)\n","        if np.float32(pred_attack[0]) == df['attack_cat'][i]:\n","            correct_pred += 1\n","\n","    # Print out results\n","    print(\"Correct Predictions(%) : {}%\".format(correct_pred * 100 / len(df['attack_cat'])))\n","    print(\"Total no. of rows: \", len(df['attack_cat']))\n","    print(\"Predicted Correctly: \", correct_pred)\n","    print(\"Wrong Predictions: \", len(df['attack_cat']) - correct_pred)\n","\n","    \n","    # --- SAVE RESULTS TO FILE --- #\n","\n","    pred_file_path = \"/content/drive/My Drive/Colab Notebooks/lite_results/prediction_results.csv\"\n","    \n","    if not os.path.exists(pred_file_path):\n","      os.makedirs('/content/drive/My Drive/Colab Notebooks/lite_results/')\n","\n","    if os.path.exists(pred_file_path) == True:\n","\n","        try:\n","            df2 = pd.read_csv(pred_file_path, encoding=\"UTF-8\") # Change encoding to UTF-16 if any errors arise\n","        except:\n","            df2 = pd.read_csv(pred_file_path, encoding=\"UTF-16\")\n","\n","\n","        now = datetime.now()\n","        date = [now.strftime(\"%d/%m/%Y %H:%M:%S\")] \n","        total_rows = [len(df['attack_cat'])]\n","        correct_preds = [correct_pred] \n","        wrong_preds = [len(df['attack_cat']) - correct_pred] \n","        success_perc = [correct_pred * 100 / len(df['attack_cat'])] \n","\n","        data = {\n","            'date': date,\n","            'total rows': total_rows,\n","            'correct predictions': correct_preds,\n","            'wrong predictions': wrong_preds,\n","            'success percentage': success_perc\n","        }\n","\n","        new_df = pd.DataFrame(data)\n","\n","        new_df.to_csv(pred_file_path, mode='a', index=False, header=False)\n","    else: \n","        now = datetime.now()\n","        date = [now.strftime(\"%d/%m/%Y %H:%M:%S\")] \n","        total_rows = [len(df['attack_cat'])]\n","        correct_preds = [correct_pred] \n","        wrong_preds = [len(df['attack_cat']) - correct_pred] \n","        success_perc = [correct_pred * 100 / len(df['attack_cat'])] \n","\n","        # dictionary of lists  \n","        dict = {'date': date, 'total rows': total_rows, 'correct predictions': correct_preds, 'wrong predictions': wrong_preds, 'success percentage': success_perc}  \n","\n","        df3 = pd.DataFrame(dict) \n","\n","        # saving the dataframe \n","        df3.to_csv(pred_file_path, index=False) \n","\n","\n","detect()\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNqeGh1C/umPs2tLbrcXkmZ"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}