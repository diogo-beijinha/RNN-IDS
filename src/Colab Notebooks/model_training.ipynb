{"cells":[{"cell_type":"markdown","metadata":{"id":"zsehaZ7S8eEh"},"source":["# Import Libs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7411,"status":"ok","timestamp":1671184923407,"user":{"displayName":"Diogo Beijinha","userId":"06164615948630766952"},"user_tz":0},"id":"dSxgknTh8bHY","outputId":"a66719ce-c0b8-40b1-8bfe-d5ae0208317e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow_model_optimization\n","  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n","\u001b[K     |████████████████████████████████| 238 kB 14.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_optimization) (1.21.6)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_optimization) (0.1.7)\n","Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.8/dist-packages (from tensorflow_model_optimization) (1.15.0)\n","Installing collected packages: tensorflow-model-optimization\n","Successfully installed tensorflow-model-optimization-0.7.3\n"]}],"source":["import os\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" #If the line below doesn't work, uncomment this line (make sure to comment the line below); it should help.\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n","'''\n","Numbers for \"os.environ['TF_CPP_MIN_LOG_LEVEL']\": \n","0 = all messages are logged (default behavior)\n","1 = INFO messages are not printed\n","2 = INFO and WARNING messages are not printed\n","3 = INFO, WARNING, and ERROR messages are not printed\n","'''\n","\n","import tensorflow\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore Pandas warnings of deprecation\n","import pandas as pd\n","pd.options.mode.chained_assignment = None  # default='warn' | Disable warnings\n","import numpy as np\n","from time import time\n","from keras.layers import Dense, Dropout, SimpleRNN, RNN, LSTM, GRU\n","from keras import Sequential, models\n","from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n","from termcolor import colored\n","import matplotlib.pyplot as plt\n","!pip install tensorflow_model_optimization\n","import tensorflow_model_optimization as tfmot"]},{"cell_type":"markdown","metadata":{"id":"S4hjTCbs8l8s"},"source":["# Import other Python files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34950,"status":"ok","timestamp":1671184958348,"user":{"displayName":"Diogo Beijinha","userId":"06164615948630766952"},"user_tz":0},"id":"QW-IpEi28rc7","outputId":"598728b2-0bbf-44ad-e3c9-7e08a2014500"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting import_ipynb\n","  Downloading import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (5.7.0)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (7.9.0)\n","Collecting jedi>=0.10\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 14.0 MB/s \n","\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.0.10)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (57.4.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (5.6.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.2.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.6.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (2.16.2)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (5.1.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.10.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.11.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import_ipynb) (2.5.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n","Installing collected packages: jedi, import-ipynb\n","Successfully installed import-ipynb-0.1.4 jedi-0.18.2\n","importing Jupyter notebook from unsw_processing.ipynb\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","importing Jupyter notebook from results_visualization.ipynb\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: import_ipynb in /usr/local/lib/python3.8/dist-packages (0.1.4)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (5.7.0)\n","Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from import_ipynb) (7.9.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.6.1)\n","Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.18.2)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (57.4.0)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (2.0.10)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (0.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (4.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->import_ipynb) (5.6.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->import_ipynb) (0.8.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (0.2.5)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import_ipynb) (1.15.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (5.1.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->import_ipynb) (2.16.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (22.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (0.19.2)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->import_ipynb) (5.10.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import_ipynb) (3.11.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core->nbformat->import_ipynb) (2.5.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->import_ipynb) (0.7.0)\n","^C\n","Num GPUs Available:  0\n","\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import sys\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/')\n","!cp -r \"/content/drive/My Drive/Colab Notebooks/unsw_processing.ipynb\" '/content/'\n","!cp -r \"/content/drive/My Drive/Colab Notebooks/results_visualization.ipynb\" '/content/'\n","\n","!pip install import_ipynb\n","import import_ipynb\n","\n","from unsw_processing import unsw_encoding\n","from results_visualization import print_results\n","\n","\n","print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))\n","print(tensorflow.test.gpu_device_name())\n"]},{"cell_type":"markdown","metadata":{"id":"cZIwMivv8ySS"},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCAFxOT8EeFf"},"outputs":[],"source":["# Values for later use\n","csv_values = ['epochs', 'acc', 'loss', 'val_acc', 'val_loss',\n","              'loss_fct', 'optimizer', 'activation_fct',\n","              'layer_nb', 'unit_nb', 'batch_size', 'dropout', 'cell_type',\n","              'encoder']\n","\n","csv_best_res = ['param', 'value', 'min_mean_val_loss']\n","\n","train_params = {'epochs': 100, \n","          'loss_fct': 'mse', \n","          'optimizer': 'rmsprop',\n","          'activation_fct': 'tanh', \n","          'layer_nb': 1, 'unit_nb': 128, \n","          'batch_size': 1024, 'dropout': 0.4,\n","          'encoder': 'labelencoder',\n","          'shuffle': True}\n","\n","\n","# ***** VARIABLE PARAMETERS *****\n","# 'encoder': ['standardscaler', 'labelencoder', 'minmaxscaler01', 'minmaxscaler11', 'ordinalencoder'],\n","# 'optimizer': ['adam', 'sgd', 'rmsprop', 'nadam', 'adamax', 'adadelta'],\n","# 'activation_fct': ['sigmoid', 'softmax', 'relu', 'tanh']\n","# 'layer_nb': [1, 2, 3, 4]\n","# 'unit_nb': [4, 8, 32, 64, 128, 256]\n","# 'dropout': [0.1, 0.2, 0.3, 0.4]\n","# 'batch_size': [512, 1024, 2048]\n","\n","\n","tf_model_path = '/content/content/tf_models'\n","res_path = \"/content/drive/My Drive/Colab Notebooks/results/\"\n","\n","# Name for results file\n","res_name = train_params['loss_fct'] + '_' + train_params['optimizer'] + '_' +\\\n","        train_params['activation_fct'] + '_' + str(train_params['layer_nb']) + '_' +\\\n","        str(train_params['unit_nb']) + '_' + str(train_params['batch_size']) + '_' +\\\n","        str(train_params['dropout']) + '_' + \"RNN\" + '_' +\\\n","        train_params['encoder'] + '_' + str(time())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q37pSr2C860o"},"outputs":[],"source":["# Encode dataset and return : x_train, x_test, y_train, y_tests\n","def load_data():\n","    x_train, x_test, y_train, y_test = unsw_encoding(train_params)\n","\n","    # Reshape the inputs in the accepted model format\n","    x_train = np.array(x_train).reshape([-1, x_train.shape[1], 1])\n","    x_test = np.array(x_test).reshape([-1, x_test.shape[1], 1])\n","    return x_train, x_test, y_train, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlYh3b7I9BIS"},"outputs":[],"source":["# Create and train a model\n","def train_model(x_train, x_test, y_train, y_test):\n","    cell = SimpleRNN #RNN\n","  \n","    # Create a Sequential layer, one layer after the other\n","    model = Sequential()\n","    # If there is more than 1 layer, the first must return sequences\n","    for _ in range(train_params['layer_nb']-1):\n","        model.add(cell(units=train_params['unit_nb'],\n","                    input_shape=(x_train.shape[1:]), return_sequences=True))\n","        model.add(Dropout(rate=train_params['dropout']))\n","\n","    # If there is only 1 layer, it must not return sequences\n","    if(train_params['layer_nb'] == 1):\n","        model.add(cell(units=train_params['unit_nb'], input_shape=x_train.shape[1:]))\n","        model.add(Dropout(rate=train_params['dropout']))\n","    else:  # If there is more than 1, the following must not return sequences\n","        model.add(cell(units=train_params['unit_nb']))\n","        model.add(Dropout(rate=train_params['dropout']))\n","    # Outputs layer\n","    model.add(Dense(units=y_train.shape[1],\n","                    activation=train_params['activation_fct']))\n","\n","    model.compile(loss=train_params['loss_fct'], optimizer=train_params['optimizer'],\n","                metrics=['accuracy'])\n","\n","    model.summary()\n","\n","    hist = model.fit(x_train, y_train, train_params['batch_size'], train_params['epochs'],\n","                    verbose=1, shuffle=train_params['shuffle'],\n","                    validation_data=(x_test, y_test), callbacks=None)\n","    \n","    save_model = ModelCheckpoint(filepath=tf_model_path + res_name,\n","                                        monitor='val_accuracy', save_best_only=True)\n","    callbacks = [save_model]\n","    model.save(tf_model_path)\n","\n","    print_results(train_params, model, x_train, x_test, y_train, y_test)\n","\n","    return hist"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"3WSdj6-D9S0f"},"outputs":[],"source":["if __name__ == \"__main__\":\n","    print(\"Loading Data\")\n","    x_train, x_test, y_train, y_test = load_data()\n","    print(\"Training Model\")\n","    history = train_model(x_train, x_test, y_train, y_test)\n","    \n","    # --- SAVE RESULTS --- #\n","    \n","    epochs = len(history.history['accuracy'])\n","    df = pd.DataFrame(columns=csv_values)\n","\n","    try:\n","      for epoch in range(epochs):\n","        df = df.append({'epochs': epoch,\n","                        'acc':  history.history['accuracy'][epoch],\n","                        'loss': history.history['loss'][epoch],\n","                        'val_acc': history.history['val_accuracy'][epoch],\n","                        'val_loss': history.history['val_loss'][epoch],\n","                        'loss_fct': train_params['loss_fct'],\n","                        'optimizer': train_params['optimizer'],\n","                        'activation_fct': train_params['activation_fct'],\n","                        'layer_nb': train_params['layer_nb'],\n","                        'unit_nb': train_params['unit_nb'],\n","                        'batch_size': train_params['batch_size'],\n","                        'dropout': train_params['dropout'],\n","                        'cell_type': \"RNN\",\n","                        'encoder': train_params['encoder']},\n","                    ignore_index=True)\n","    except Exception as e:\n","      print(\"Could not append to df due to {}\".format(colored(e, 'red')))\n","    \n","    res_name = train_params['loss_fct'] + '_' + train_params['optimizer'] + '_' +\\\n","        train_params['activation_fct'] + '_' + str(train_params['layer_nb']) + '_' +\\\n","        str(train_params['unit_nb']) + '_' + str(train_params['batch_size']) + '_' +\\\n","        str(train_params['dropout']) + '_' + \"RNN\" + '_' +\\\n","        train_params['encoder'] + '_' + str(time())\n","        \n","    # Errors occur without this\n","    if not os.path.exists(res_path):\n","        os.makedirs(res_path)\n","  \n","    full_res_path = res_path + \"model_full_results_\" + res_name + \".csv\"\n","    df.to_csv(full_res_path, index=False)\n"]},{"cell_type":"code","source":["# --- Charts --- # \n","    # Accuracy Chart\n","    plt.plot(history.history['accuracy'], label='accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.ylim([0.5, 1])\n","    plt.xlim([0, epochs])\n","    plt.legend(loc='lower right')\n","    plt.show()\n","\n","    # Loss Chart\n","    plt.plot(history.history['loss'], label='loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.ylim([0.01, 0.1])\n","    plt.xlim([0, epochs])\n","    plt.legend(loc='lower right')\n","    plt.show()"],"metadata":{"id":"R5rfA_KIfQe4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wnn699Z7ymng"},"source":["# Save models to Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDd8_lk2YB6-"},"outputs":[],"source":["!cp -r \"/content/content/tf_models\" \"/content/drive/My Drive/Colab Notebooks/\""]},{"cell_type":"markdown","metadata":{"id":"xkhHk4azS9DJ"},"source":["# Quantize Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqchXMmTrtYf"},"outputs":[],"source":["from google.colab import drive\n","import sys\n","import tensorflow as tf\n","from keras import Sequential, models\n","!pip install tensorflow_model_optimization\n","import tensorflow_model_optimization as tfmot\n","\n","\n","# RUN PREVIOUS CODE BLOCK BEFORE RUNNING THIS\n","# THIS CODE QUANTIZES THE CURRENT SAVED MODEL IN THE DRIVE FOLDER\n","\n","# Get files from Drive\n","drive.mount('/content/drive')\n","sys.path.append('/content/drive/My Drive/Colab Notebooks/')\n","!cp -r \"/content/drive/My Drive/Colab Notebooks/tf_models/\" '/content/'\n","\n","# Normal Model without Quantization\n","loaded_model = models.load_model('/content/tf_models')\n","print(loaded_model.summary())\n","\n","# Helper function uses `quantize_annotate_layer` to annotate that only the Dense layers should be quantized.\n","def apply_quantization_to_dense(layer):\n","  if isinstance(layer, tf.keras.layers.Dense):\n","    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n","  return layer\n","\n","# Use `tf.keras.models.clone_model` to apply `apply_quantization_to_dense` to the layers of the model.\n","annotated_model = tf.keras.models.clone_model(\n","    loaded_model,\n","    clone_function=apply_quantization_to_dense,\n",")\n","\n","# Now that the Dense layers are annotated, `quantize_apply` actually makes the model quantization aware.\n","quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)\n","print(quant_aware_model.summary())\n","loaded_model.compile(loss=train_params['loss_fct'], optimizer=train_params['optimizer'],\n","                metrics=['accuracy'])\n","\n","\n","quant_aware_model.save(\"/content/quant_model\")\n","!cp -r \"/content/quant_model/\" '/content/drive/My Drive/Colab Notebooks/'"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}